"""Tests for multi-source functionality in the data pipeline."""

from __future__ import annotations

import os
import tempfile
from datetime import datetime
from unittest.mock import Mock, patch

import pandas as pd
import pytest

from bot.dataflow.pipeline import (
    CSVFileSource,
    DataPipeline,
    DataSourceConfig,
    DataSourceType,
    MultiSourceConfig,
)


class TestDataSourceConfig:
    """Test data source configuration."""

    def test_default_config(self):
        config = DataSourceConfig(DataSourceType.YFINANCE)

        assert config.source_type == DataSourceType.YFINANCE
        assert config.priority == 1
        assert config.timeout_seconds == 30.0
        assert config.max_retries == 3
        assert config.enabled is True
        assert config.config_params == {}

    def test_custom_config(self):
        config = DataSourceConfig(
            source_type=DataSourceType.CSV_FILE,
            priority=2,
            timeout_seconds=60.0,
            max_retries=5,
            enabled=False,
            config_params={"file_path": "/path/to/file.csv"},
        )

        assert config.source_type == DataSourceType.CSV_FILE
        assert config.priority == 2
        assert config.timeout_seconds == 60.0
        assert config.max_retries == 5
        assert config.enabled is False
        assert config.config_params == {"file_path": "/path/to/file.csv"}


class TestMultiSourceConfig:
    """Test multi-source configuration."""

    def test_default_config(self):
        config = MultiSourceConfig()

        assert len(config.sources) == 1
        assert config.sources[0].source_type == DataSourceType.YFINANCE
        assert config.failover_enabled is True
        assert config.parallel_fetch is False
        assert config.primary_source_timeout == 10.0
        assert config.fallback_source_timeout == 30.0

    def test_custom_config(self):
        sources = [
            DataSourceConfig(DataSourceType.YFINANCE, priority=2),
            DataSourceConfig(DataSourceType.ENHANCED_YFINANCE, priority=1),
        ]

        config = MultiSourceConfig(sources=sources, failover_enabled=False, parallel_fetch=True)

        # Should sort by priority
        assert len(config.sources) == 2
        assert config.sources[0].source_type == DataSourceType.ENHANCED_YFINANCE
        assert config.sources[1].source_type == DataSourceType.YFINANCE
        assert config.failover_enabled is False
        assert config.parallel_fetch is True

    def test_priority_sorting(self):
        sources = [
            DataSourceConfig(DataSourceType.YFINANCE, priority=3),
            DataSourceConfig(DataSourceType.ENHANCED_YFINANCE, priority=1),
            DataSourceConfig(DataSourceType.CSV_FILE, priority=2),
        ]

        config = MultiSourceConfig(sources=sources)

        # Should be sorted by priority (ascending)
        priorities = [s.priority for s in config.sources]
        assert priorities == [1, 2, 3]


class TestCSVFileSource:
    """Test CSV file data source."""

    @pytest.fixture
    def sample_csv_file(self):
        """Create a temporary CSV file for testing."""
        data = {
            "Date": ["2023-01-01", "2023-01-02", "2023-01-03"],
            "Open": [100.0, 101.0, 102.0],
            "High": [105.0, 106.0, 107.0],
            "Low": [95.0, 96.0, 97.0],
            "Close": [102.0, 103.0, 104.0],
            "Volume": [1000, 1100, 1200],
            "Symbol": ["TEST", "TEST", "TEST"],
        }

        df = pd.DataFrame(data)

        # Create temporary file
        fd, temp_path = tempfile.mkstemp(suffix=".csv")
        try:
            df.to_csv(temp_path, index=False)
            yield temp_path
        finally:
            os.close(fd)
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    def test_csv_source_initialization(self, sample_csv_file):
        source = CSVFileSource(sample_csv_file)

        assert source.file_path == sample_csv_file
        assert source.date_column == "Date"
        assert source._data_cache is None

    def test_csv_source_data_loading(self, sample_csv_file):
        source = CSVFileSource(sample_csv_file)

        df = source.get_daily_bars("TEST", "2023-01-01", "2023-01-03")

        assert not df.empty
        assert len(df) == 3
        assert "Open" in df.columns
        assert "High" in df.columns
        assert "Low" in df.columns
        assert "Close" in df.columns
        assert isinstance(df.index, pd.DatetimeIndex)

    def test_csv_source_date_filtering(self, sample_csv_file):
        source = CSVFileSource(sample_csv_file)

        # Get subset of dates
        df = source.get_daily_bars("TEST", "2023-01-02", "2023-01-02")

        assert len(df) == 1
        assert df["Close"].iloc[0] == 103.0

    def test_csv_source_symbol_filtering(self, sample_csv_file):
        source = CSVFileSource(sample_csv_file)

        # This should work since all symbols are 'TEST'
        df = source.get_daily_bars("TEST", "2023-01-01", "2023-01-03")
        assert len(df) == 3

        # This should return empty since no symbol 'OTHER' exists
        df = source.get_daily_bars("OTHER", "2023-01-01", "2023-01-03")
        assert len(df) == 0

    def test_csv_source_missing_file(self):
        source = CSVFileSource("/nonexistent/path.csv")

        df = source.get_daily_bars("TEST", "2023-01-01", "2023-01-03")

        assert df.empty


class TestMultiSourceDataPipeline:
    """Test multi-source data pipeline functionality."""

    @pytest.fixture
    def mock_yfinance_source(self):
        mock = Mock()
        mock.get_daily_bars.return_value = pd.DataFrame(
            {"Open": [100.0], "High": [105.0], "Low": [95.0], "Close": [102.0], "Volume": [1000]},
            index=pd.DatetimeIndex(["2023-01-01"]),
        )
        return mock

    @pytest.fixture
    def mock_enhanced_source(self):
        mock = Mock()
        mock.get_daily_bars.return_value = pd.DataFrame(
            {"Open": [200.0], "High": [205.0], "Low": [195.0], "Close": [202.0], "Volume": [2000]},
            index=pd.DatetimeIndex(["2023-01-01"]),
        )
        return mock

    def test_multi_source_initialization(self):
        config = MultiSourceConfig(
            sources=[
                DataSourceConfig(DataSourceType.YFINANCE, priority=1),
                DataSourceConfig(DataSourceType.ENHANCED_YFINANCE, priority=2),
            ]
        )

        with patch("src.bot.dataflow.pipeline.YFinanceSource") as mock_yf:
            pipeline = DataPipeline(multi_source_config=config)

            # Should have attempted to initialize YFinance source
            mock_yf.assert_called()

            # Should have source info
            source_info = pipeline.get_source_info()
            assert source_info["total_sources"] == 2
            assert source_info["failover_enabled"] is True

    def test_source_failover(self):
        config = MultiSourceConfig(
            sources=[
                DataSourceConfig(DataSourceType.YFINANCE, priority=1),
                DataSourceConfig(DataSourceType.ENHANCED_YFINANCE, priority=2),
            ],
            failover_enabled=True,
        )

        # Mock first source to fail, second to succeed
        with patch("src.bot.dataflow.pipeline.YFinanceSource") as mock_yf_class:
            mock_primary = Mock()
            mock_primary.get_daily_bars.side_effect = Exception("Primary failed")

            mock_fallback = Mock()
            mock_fallback.get_daily_bars.return_value = pd.DataFrame(
                {
                    "Open": [100.0],
                    "High": [105.0],
                    "Low": [95.0],
                    "Close": [102.0],
                    "Volume": [1000],
                },
                index=pd.DatetimeIndex(["2023-01-01"]),
            )

            # Configure the mock to return different instances
            mock_yf_class.side_effect = [mock_primary, mock_fallback]

            pipeline = DataPipeline(multi_source_config=config)

            # Manually set up sources to simulate the scenario
            pipeline.data_sources = {
                DataSourceType.YFINANCE: mock_primary,
                DataSourceType.ENHANCED_YFINANCE: mock_fallback,
            }

            with patch("src.bot.dataflow.validate.validate_daily_bars"):
                with patch("src.bot.dataflow.validate.adjust_to_adjclose") as mock_adjust:
                    mock_adjust.return_value = (mock_fallback.get_daily_bars.return_value, False)

                    # This should succeed using the fallback source
                    data = pipeline.fetch_and_validate(
                        ["AAPL"], datetime(2023, 1, 1), datetime(2023, 1, 31)
                    )

                    assert len(data) == 1
                    assert "AAPL" in data

                    # Both sources should have been attempted
                    mock_primary.get_daily_bars.assert_called()
                    mock_fallback.get_daily_bars.assert_called()

    def test_failover_disabled(self):
        config = MultiSourceConfig(
            sources=[DataSourceConfig(DataSourceType.YFINANCE, priority=1)], failover_enabled=False
        )

        with patch("src.bot.dataflow.pipeline.YFinanceSource") as mock_yf_class:
            mock_source = Mock()
            mock_source.get_daily_bars.side_effect = Exception("Source failed")
            mock_yf_class.return_value = mock_source

            pipeline = DataPipeline(multi_source_config=config)

            # This should fail since failover is disabled and source fails
            with pytest.raises(ValueError, match="No data could be loaded"):
                pipeline.fetch_and_validate(["AAPL"], datetime(2023, 1, 1), datetime(2023, 1, 31))

    def test_add_custom_data_source(self):
        pipeline = DataPipeline()

        # Create a custom mock source
        custom_source = Mock()
        custom_source.get_daily_bars.return_value = pd.DataFrame(
            {"Open": [300.0], "High": [305.0], "Low": [295.0], "Close": [302.0], "Volume": [3000]},
            index=pd.DatetimeIndex(["2023-01-01"]),
        )

        # Add custom source
        custom_type = DataSourceType.CSV_FILE  # Using existing enum value
        pipeline.add_data_source(custom_type, custom_source, priority=1)

        # Should be added to sources
        assert custom_type in pipeline.data_sources
        assert pipeline.data_sources[custom_type] == custom_source

        # Should be in configuration
        source_info = pipeline.get_source_info()
        custom_sources = [s for s in source_info["sources"] if s["type"] == custom_type.value]
        assert len(custom_sources) == 1
        assert custom_sources[0]["priority"] == 1

    def test_get_source_info(self):
        config = MultiSourceConfig(
            sources=[
                DataSourceConfig(DataSourceType.YFINANCE, priority=1, enabled=True),
                DataSourceConfig(DataSourceType.ENHANCED_YFINANCE, priority=2, enabled=False),
            ],
            failover_enabled=True,
            parallel_fetch=False,
        )

        with patch("src.bot.dataflow.pipeline.YFinanceSource"):
            pipeline = DataPipeline(multi_source_config=config)

            info = pipeline.get_source_info()

            assert info["total_sources"] == 2
            assert info["failover_enabled"] is True
            assert info["parallel_fetch"] is False
            assert "primary_source" in info

            # Check individual source info
            sources = info["sources"]
            assert len(sources) == 2

            yf_source = next(s for s in sources if s["type"] == "yfinance")
            assert yf_source["priority"] == 1
            assert yf_source["enabled"] is True

            enhanced_source = next(s for s in sources if s["type"] == "enhanced_yfinance")
            assert enhanced_source["priority"] == 2
            assert enhanced_source["enabled"] is False

    def test_csv_source_integration(self):
        """Test integration of CSV source with pipeline."""
        # Create temporary CSV file
        data = {
            "Date": ["2023-01-01", "2023-01-02"],
            "Open": [100.0, 101.0],
            "High": [105.0, 106.0],
            "Low": [95.0, 96.0],
            "Close": [102.0, 103.0],
            "Volume": [1000, 1100],
            "Symbol": ["TEST", "TEST"],
        }
        df = pd.DataFrame(data)

        fd, temp_path = tempfile.mkstemp(suffix=".csv")
        try:
            df.to_csv(temp_path, index=False)

            config = MultiSourceConfig(
                sources=[
                    DataSourceConfig(
                        source_type=DataSourceType.CSV_FILE,
                        priority=1,
                        config_params={"file_path": temp_path, "date_column": "Date"},
                    )
                ]
            )

            pipeline = DataPipeline(multi_source_config=config)

            with patch("src.bot.dataflow.validate.validate_daily_bars"):
                with patch("src.bot.dataflow.validate.adjust_to_adjclose") as mock_adjust:
                    mock_adjust.return_value = (df.set_index("Date"), False)

                    data = pipeline.fetch_and_validate(
                        ["TEST"], datetime(2023, 1, 1), datetime(2023, 1, 2)
                    )

                    assert len(data) == 1
                    assert "TEST" in data
                    assert len(data["TEST"]) >= 1  # Should have at least some data

        finally:
            os.close(fd)
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    def test_source_priority_ordering(self):
        """Test that sources are tried in priority order."""
        config = MultiSourceConfig(
            sources=[
                DataSourceConfig(DataSourceType.ENHANCED_YFINANCE, priority=3),
                DataSourceConfig(DataSourceType.YFINANCE, priority=1),
                DataSourceConfig(DataSourceType.CSV_FILE, priority=2),
            ]
        )

        # Create a pipeline and check that sources are ordered correctly
        with patch("src.bot.dataflow.pipeline.YFinanceSource"):
            pipeline = DataPipeline(multi_source_config=config)

            # Check that sources are in priority order
            priorities = [s.priority for s in pipeline.multi_source_config.sources]
            assert priorities == [1, 2, 3]

            types = [s.source_type for s in pipeline.multi_source_config.sources]
            expected_types = [
                DataSourceType.YFINANCE,
                DataSourceType.CSV_FILE,
                DataSourceType.ENHANCED_YFINANCE,
            ]
            assert types == expected_types
