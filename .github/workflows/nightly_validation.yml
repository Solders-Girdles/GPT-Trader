name: Nightly Validation

on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  actions: write
  issues: write
  statuses: write

defaults:
  run:
    shell: bash --noprofile --norc {0}

env:
  PYTHON_VERSION: "3.12"

jobs:
  integration-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v6

      - name: Prepare Python environment
        id: setup-uv
        uses: ./.github/actions/setup-uv
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run integration tests
        run: |
          set -euo pipefail
          uv run pytest tests/integration -m integration -v --tb=short

      - name: Report status
        if: failure()
        uses: actions/github-script@v8
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ðŸš¨ Nightly integration tests failed',
              body: 'The nightly integration tests detected a regression. Check the [workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details.',
              labels: ['bug', 'integration', 'nightly']
            })

  full-test-suite:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v6

      - name: Prepare Python environment
        id: setup-uv
        uses: ./.github/actions/setup-uv
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run full test suite (parallel)
        uses: nick-invision/retry@v3
        with:
          timeout_minutes: 45
          max_attempts: 2
          retry_wait_seconds: 10
          command: uv run pytest -n auto --dist worksteal -q

      - name: Report status
        if: failure()
        uses: actions/github-script@v8
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ðŸš¨ Nightly full test suite failed',
              body: 'The nightly full test suite (including slow tests) has failed. Check the [workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) for details.',
              labels: ['bug', 'tests', 'nightly']
            })

      - name: Generate workflow summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## Nightly Full Test Suite

          | Metric | Value |
          |--------|-------|
          | Test Mode | Parallel (pytest-xdist) |
          | Distribution | worksteal |
          EOF

          echo "| Timestamp | $(date -u '+%Y-%m-%d %H:%M:%S UTC') |" >> $GITHUB_STEP_SUMMARY

  property-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v6

      - name: Prepare Python environment
        uses: ./.github/actions/setup-uv
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run property-based tests
        run: |
          set -euo pipefail
          if [ -d tests/property ]; then
            uv run pytest tests/property/ -v \
              --hypothesis-seed=0 \
              --hypothesis-show-statistics
          else
            echo "No property tests directory found, skipping"
          fi

      - name: Upload hypothesis artifacts
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: hypothesis-examples
          path: .hypothesis/
          retention-days: 7
          if-no-files-found: ignore

  performance-benchmarks:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v6

      - name: Prepare Python environment
        uses: ./.github/actions/setup-uv
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run benchmarks
        run: |
          set -euo pipefail
          uv run pytest tests/ -m "perf or performance" \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --benchmark-compare-fail=mean:10% || echo "::warning::Performance regression detected or no benchmarks found"

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: benchmark-results
          path: benchmark-results.json
          retention-days: 30
          if-no-files-found: ignore

  security-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v6

      - name: Prepare Python environment
        uses: ./.github/actions/setup-uv
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Security scan with Bandit
        run: |
          set -euo pipefail
          uv run bandit -r src/gpt_trader/ \
            --severity-level medium \
            --confidence-level medium \
            -f json -o bandit-nightly.json

      - name: Dependency audit with pip-audit
        run: |
          set -euo pipefail
          uv run pip-audit -f json -o pip-audit-nightly.json --ignore-vuln GHSA-4xh5-x5gv-qwph || echo "pip-audit completed with warnings"

      - name: Upload security reports
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: nightly-security-reports
          path: |
            bandit-nightly.json
            pip-audit-nightly.json
          retention-days: 30

  compatibility-tests:
    name: Python Compatibility
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.12", "3.13"]
    steps:
      - uses: actions/checkout@v6

      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true

      - name: Install dependencies
        run: uv sync --frozen

      - name: Run compatibility tests
        run: |
          set -euo pipefail
          uv run pytest tests/unit -q -x --ignore=tests/unit/gpt_trader/features \
            -m "not slow and not performance" \
            || echo "::warning::Some tests failed on Python ${{ matrix.python-version }}"

      - name: Generate compatibility summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## Python ${{ matrix.python-version }} Compatibility

          | Check | Result |
          |-------|--------|
          | Dependencies | $(uv pip list | wc -l) packages installed |
          | Python Version | $(python --version) |
          EOF

  notify-completion:
    name: Nightly Summary
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [integration-tests, full-test-suite, property-tests, performance-benchmarks, security-scan, compatibility-tests]
    if: always()
    steps:
      - name: Check job results
        id: results
        run: |
          # Collect results from all jobs
          results="${{ needs.integration-tests.result }},${{ needs.full-test-suite.result }},${{ needs.property-tests.result }},${{ needs.performance-benchmarks.result }},${{ needs.security-scan.result }},${{ needs.compatibility-tests.result }}"

          if echo "$results" | grep -q "failure"; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "emoji=ðŸš¨" >> $GITHUB_OUTPUT
          elif echo "$results" | grep -q "cancelled"; then
            echo "status=cancelled" >> $GITHUB_OUTPUT
            echo "emoji=âš ï¸" >> $GITHUB_OUTPUT
          else
            echo "status=success" >> $GITHUB_OUTPUT
            echo "emoji=âœ…" >> $GITHUB_OUTPUT
          fi

      - name: Generate nightly summary
        run: |
          cat >> $GITHUB_STEP_SUMMARY << EOF
          # ${{ steps.results.outputs.emoji }} Nightly Validation Summary

          | Job | Status |
          |-----|--------|
          | Integration Tests | ${{ needs.integration-tests.result }} |
          | Full Test Suite | ${{ needs.full-test-suite.result }} |
          | Property Tests | ${{ needs.property-tests.result }} |
          | Performance Benchmarks | ${{ needs.performance-benchmarks.result }} |
          | Security Scan | ${{ needs.security-scan.result }} |
          | Compatibility Tests | ${{ needs.compatibility-tests.result }} |

          **Overall Status**: ${{ steps.results.outputs.status }}
          **Completed**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')
          EOF

      - name: Create success commit status
        if: steps.results.outputs.status == 'success'
        uses: actions/github-script@v8
        with:
          script: |
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: 'success',
              description: 'All nightly validation checks passed',
              context: 'nightly/validation'
            })
